Although considerable research has been done on the brain networks specialized for visual processing of tools and bodies and the visual-motor processing of hand actions, these topics have largely been studied in isolation.
It remains unclear whether the highly specialized brain areas within these tool-, body-, and action-related networks in humans also play important roles in planning real movements with a tool or with the body (hand) alone.
The present findings provide insights into where different brain regions might be situated within such a hierarchy.
In addition to providing insights into how action-centred behavior is cortically represented (discussed above) these findings offer a new lens through which to view findings reported from previous observation-based fMRI studies.
Given the delay of incoming sensory signals, this type of forward-state estimation is featured prominently in models of action control (Wolpert and Ghahramani, 2000; Wolpert and Flanagan, 2001) and, from the standpoint of perception, predicting the sensory consequences of movement can be used to disambiguate movements of the body (self) vs movements of the world (others) (von Helmohltz, 1866).
Updating the considerably simpler notion that action planning, particularly in the case of tool use, merely involves ‘access’ to ventral stream resources (Milner and Goodale, 1995; Valyear and Culham, 2010), these findings show that hand- and tool-related action plans can actually be decoded from preparatory signals in body- and tool-selective occipitotemporal cortex areas.
        In addition to suggesting a role for OTC in visual-motor planning, these findings might also shed light on the organizing principles of the ventral visual stream.
More specifically, by training a pattern classifier to discriminate grasp vs reach movements with one effector (e.g., hand) and then testing whether that same classifier can be used to predict the same trial types with the other effector (e.g., tool), we could assess whether the object-directed action being planned (grasping vs reaching) was being represented with some level of invariance to the effector being used to perform the movement (see ‘Across-effector classification’ below for further details).
        
        
          
          MVPA was performed with a combination of in-house software (using Matlab) and the Princeton MVPA Toolbox for Matlab (http://code.google.com/p/princeton-mvpa-toolbox/) using a Support Vector Machines (SVM) binary classifier (libSVM, http://www.csie.ntu.edu.tw/~cjlin/libsvm/).
